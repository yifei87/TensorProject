# 如何使用TF-Hub构建简单的文本分类器

注意：您可以使用零设置在Collab中运行[此笔记本](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/text_classification_with_tf_hub.ipynb)。

TF-Hub是一个分享机器学习专业知识的平台，其中包含可重复使用的资源，特别是预先培训的模块。 本教程分为两个主要部分。

- **简介：使用TF-Hub训练文本分类器**
我们将使用TF-Hub文本嵌入模块来训练具有合理基线准确度的简单情感分类器。 然后，我们将分析这些预测，以确保我们的模型是合理的，并提出改进以提高准确性。

- **高级：迁移学习分析**
在本节中，我们将使用各种TF-Hub模块来比较它们对估算器准确度的影响，并展示转移学习的优势和缺陷。

## Optional prerequisites
- 对Tensorflow[预制估算框架](https://tensorflow.google.cn/get_started/premade_estimators)的基本理解。
- 熟悉[pandas](https://pandas.pydata.org/)。

![这里写图片描述](https://tensorflow.google.cn/images/tensorflow_programming_environment.png)

## Preparing the enviroment

```python
# Install the latest Tensorflow version.
# Install TF-Hub.
!pip install -q tensorflow-hub

```

```python
import tensorflow as tf
import tensorflow_hub as hub
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import re
import seaborn as sns

```

## Getting started
### Data
我们将尝试解决Mass等人的[Large Movie Review Dataset v1.0](http://ai.stanford.edu/~amaas/data/sentiment/)任务。 该数据集包含IMDB电影评论，标记为1到10的积极性。任务是将评论标记为否定或肯定。

```python
# Load all files from a directory in a DataFrame.
def load_directory_data(directory):
  data = {}
  data["sentence"] = []
  data["sentiment"] = []
  for file_path in os.listdir(directory):
    with tf.gfile.GFile(os.path.join(directory, file_path), "r") as f:
      data["sentence"].append(f.read())
      data["sentiment"].append(re.match("\d+_(\d+)\.txt", file_path).group(1))
  return pd.DataFrame.from_dict(data)

# Merge positive and negative examples, add a polarity column and shuffle.
def load_dataset(directory):
  pos_df = load_directory_data(os.path.join(directory, "pos"))
  neg_df = load_directory_data(os.path.join(directory, "neg"))
  pos_df["polarity"] = 1
  neg_df["polarity"] = 0
  return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)

# Download and process the dataset files.
def download_and_load_datasets(force_download=False):
  dataset = tf.keras.utils.get_file(
      fname="aclImdb.tar.gz", 
      origin="http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz", 
      extract=True)

  train_df = load_dataset(os.path.join(os.path.dirname(dataset), 
                                       "aclImdb", "train"))
  test_df = load_dataset(os.path.join(os.path.dirname(dataset), 
                                      "aclImdb", "test"))

  return train_df, test_df

# Reduce logging output.
tf.logging.set_verbosity(tf.logging.ERROR)

train_df, test_df = download_and_load_datasets()
train_df.head()

```

## Model
### Input functions

[Estimator框架](https://tensorflow.google.cn/get_started/premade_estimators#overview_of_programming_with_estimators)提供包装Pandas数据框的[输入函数](https://tensorflow.google.cn/api_docs/python/tf/estimator/inputs/pandas_input_fn)。

```python
# Training input on the whole training set with no limit on training epochs.
train_input_fn = tf.estimator.inputs.pandas_input_fn(
    train_df, train_df["polarity"], num_epochs=None, shuffle=True)

# Prediction on the whole training set.
predict_train_input_fn = tf.estimator.inputs.pandas_input_fn(
    train_df, train_df["polarity"], shuffle=False)
# Prediction on the test set.
predict_test_input_fn = tf.estimator.inputs.pandas_input_fn(
    test_df, test_df["polarity"], shuffle=False)

```

### Feature columns
TF-Hub提供了一个[功能栏](https://github.com/tensorflow/hub/blob/r0.1/docs/api_docs/python/hub/text_embedding_column)，可在给定的文本功能上应用模块，并进一步传递模块的输出。 在本教程中，我们将使用[nnlm-en-dim128模块](https://tfhub.dev/google/nnlm-en-dim128/1)。 为了本教程的目的，最重要的事实是：

- 该模块将一批字符串作为输入，以一维张量作为输入。
- 该模块负责对句子进行预处理（例如删除标点符号和分隔空格）。
- 该模块可以处理任何输入（例如，nnlm-en-dim128将单词中不存在的单词放入〜20.000桶中）。

```python
embedded_text_feature_column = hub.text_embedding_column(
    key="sentence", 
    module_spec="https://tfhub.dev/google/nnlm-en-dim128/1")

```

### Estimator
对于分类，我们可以使用[DNN分类器](https://tensorflow.google.cn/api_docs/python/tf/estimator/DNNClassifier)（注意关于本教程末尾不同的标签功能建模的进一步说明）。

```
estimator = tf.estimator.DNNClassifier(
    hidden_units=[500, 100],
    feature_columns=[embedded_text_feature_column],
    n_classes=2,
    optimizer=tf.train.AdagradOptimizer(learning_rate=0.003))

```
### Training
训练estimator进行合理的步骤。

```python
# Training for 1,000 steps means 128,000 training examples with the default
# batch size. This is roughly equivalent to 5 epochs since the training dataset
# contains 25,000 examples.
estimator.train(input_fn=train_input_fn, steps=1000);

```
## Prediction
运行训练和测试集的预测。

```python
train_eval_result = estimator.evaluate(input_fn=predict_train_input_fn)
test_eval_result = estimator.evaluate(input_fn=predict_test_input_fn)

print "Training set accuracy: {accuracy}".format(**train_eval_result)
print "Test set accuracy: {accuracy}".format(**test_eval_result)

```

## Confusion matrix
我们可以通过视觉检查混淆矩阵来了解错误分类的分布。

```python
def get_predictions(estimator, input_fn):
  return [x["class_ids"][0] for x in estimator.predict(input_fn=input_fn)]

LABELS = [
    "negative", "positive"
]

# Create a confusion matrix on training data.
with tf.Graph().as_default():
  cm = tf.confusion_matrix(train_df["polarity"], 
                           get_predictions(estimator, predict_train_input_fn))
  with tf.Session() as session:
    cm_out = session.run(cm)

# Normalize the confusion matrix so that each row sums to 1.
cm_out = cm_out.astype(float) / cm_out.sum(axis=1)[:, np.newaxis]

sns.heatmap(cm_out, annot=True, xticklabels=LABELS, yticklabels=LABELS);
plt.xlabel("Predicted");
plt.ylabel("True");

```
![这里写图片描述](https://tensorflow.google.cn/tutorials/text_classification_with_tf_hub_files/output_19_0.png)

## Further improvements
1、情绪回归：我们使用分类器将每个例子分配到一个极性类。 但我们实际上还有另一个明确的特征 - 情绪。 这里的课程实际上代表了一个规模，而潜在的价值（正面/负面）可以很好地映射到一个连续的范围内。 我们可以通过计算回归（[DNN Regressor](https://tensorflow.google.cn/api_docs/python/tf/contrib/learn/DNNRegressor)）而不是分类（[DNN分类器](https://tensorflow.google.cn/api_docs/python/tf/contrib/learn/DNNClassifier)）来利用此属性。

2、更大的模块：为了本教程的目的，我们使用了一个小模块来限制内存的使用。 有更大的词汇表和更大的嵌入空间的模块可以提供更多的准确性点。

3、参数调整：我们可以通过调整学习速率或步数等元参数来提高准确性，特别是如果我们使用不同的模块。 如果我们想获得任何合理的结果，验证集非常重要，因为建立一个模型可以很容易地学会预测训练数据，而不会很好地对测试集进行概括。

4、更复杂的模型：我们使用了一个模块，通过嵌入每个单词，然后将它们与平均值相结合来计算句子嵌入。 人们还可以使用顺序模块（例如，[通用句子编码器模块](https://tfhub.dev/google/universal-sentence-encoder/1)）来更好地捕捉句子的性质。 或者是两个或更多TF-Hub模块的合奏。

5、正则化：为了防止过度拟合，我们可以尝试使用做某种正则化的优化器，例如[Proximal Adagrad Optimizer](https://tensorflow.google.cn/api_docs/python/tf/train/ProximalAdagradOptimizer)。

## Advanced: Transfer learning analysis
迁移学习可以节省培训资源并实现良好的模型泛化，即使在小数据集上进行培训时也是如此。 在这一部分，我们将通过两种不同的TF-Hub模块进行训练来证明这一点：

- [nnlm-en-dim128](https://tfhub.dev/google/nnlm-en-dim128/1) - 预训练文本嵌入模块，
-     [random-nnlm-en-dim128](https://tfhub.dev/google/random-nnlm-en-dim128/1) - 与nnlm-en-dim128具有相同词汇表和网络的文本嵌入模块，但权重只是随机初始化的，并且从不受真实数据的训练。

并通过两种模式进行培训：

     - 只训练分类器（即冻结模块），和
     - 与模块一起训练分类器。

让我们进行一些培训和评估，看看如何使用各种模块来影响准确性。

```python
def train_and_evaluate_with_module(hub_module, train_module=False):
  embedded_text_feature_column = hub.text_embedding_column(
      key="sentence", module_spec=hub_module, trainable=train_module)

  estimator = tf.estimator.DNNClassifier(
      hidden_units=[500, 100],
      feature_columns=[embedded_text_feature_column],
      n_classes=2,
      optimizer=tf.train.AdagradOptimizer(learning_rate=0.003))

  estimator.train(input_fn=train_input_fn, steps=1000)

  train_eval_result = estimator.evaluate(input_fn=predict_train_input_fn)
  test_eval_result = estimator.evaluate(input_fn=predict_test_input_fn)

  training_set_accuracy = train_eval_result["accuracy"]
  test_set_accuracy = test_eval_result["accuracy"]

  return {
      "Training accuracy": training_set_accuracy,
      "Test accuracy": test_set_accuracy
  }

results = {}
results["nnlm-en-dim128"] = train_and_evaluate_with_module(
    "https://tfhub.dev/google/nnlm-en-dim128/1")
results["nnlm-en-dim128-with-module-training"] = train_and_evaluate_with_module(
    "https://tfhub.dev/google/nnlm-en-dim128/1", True)
results["random-nnlm-en-dim128"] = train_and_evaluate_with_module(
    "https://tfhub.dev/google/random-nnlm-en-dim128/1")
results["random-nnlm-en-dim128-with-module-training"] = train_and_evaluate_with_module(
    "https://tfhub.dev/google/random-nnlm-en-dim128/1", True)

```

让我们看看结果。

```
pd.DataFrame.from_dict(results, orient="index")
```

我们已经可以看到一些模式，但首先我们应该建立测试集的基线准确性 - 通过只输出最具代表性的类的标签可以实现的下限：

```
estimator.evaluate(input_fn=predict_test_input_fn)["accuracy_baseline"]
```

分配最具代表性的class将为我们提供50％的准确性。 有几件事情需要注意：

- 也许令人惊讶的是，一个模型仍然可以在固定的随机嵌入之上学习。 原因是即使字典中的每个词都映射到一个随机向量，估计器也可以纯粹使用其完全连接的层分离空间。
- 允许使用随机嵌入对模块进行训练可以提高训练和测试的准确性，因为它们只是对分类器进行训练。
-      使用预先训练的嵌入对模块进行训练也会提高准确度。 但请注意训练集上的过度训练。 即使在正规化的情况下，训练预先训练的模块也是危险的，因为嵌入权重不再代表在不同数据上训练的语言模型，而是收敛到新数据集的理想表示。
